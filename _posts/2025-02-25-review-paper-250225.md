---
revision: 0
title: "[리뷰] Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieval (MM 2024)"
category: programming
tags:
  - review
created_at: 2025-02-23 16:57:28 +09:00
last_modified_at: 2025-02-23 16:57:28 +09:00
excerpt: "논문 리뷰 - 0223"
---

# Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieval (MM 2024)


### 논문 요약 및 설명:  


#### **1. 개요 (Abstract)**  
본 논문은 **Scene Text Retrieval (STR, 장면 내 텍스트 검색)**을 위한 새로운 접근법을 제안합니다. 기존 방법들은 Optical Character Recognition (OCR) 기반의 복잡한 파이프라인을 사용하여 검색을 수행하지만, 이는 비효율적이고 유연성이 부족한 문제가 있습니다. 이를 해결하기 위해 **Contrastive Language-Image Pre-training (CLIP)** 모델의 잠재력을 활용하여 **OCR-free** STR 방법을 개발합니다.  
논문에서는 CLIP을 STR 모델로 적용할 때 두 가지 주요 문제가 있음을 발견했습니다.
1. **제한된 텍스트 인식 범위** (Limited text perceptual scale): CLIP의 이미지 해상도가 낮아 장면 내 작은 텍스트를 인식하는 데 어려움이 있음.
2. **시각-언어 개념 얽힘** (Entangled visual-semantic concepts): CLIP이 이미지 내 시각적인 요소와 언어적 개념을 혼동하는 경향이 있음.

이를 해결하기 위해 FDP(Focus, Distinguish, and Prompt) 모델을 제안하며, 해당 모델은 다음의 세 가지 핵심 단계로 구성됩니다:
- **Focus (집중)**: CLIP이 이미지 내 텍스트 부분에 더 집중하도록 유도.
- **Distinguish (구별)**: 검색할 텍스트를 의미론적으로 구분 (예: 의미가 명확한 "content words" vs. 기능적인 "function words").
- **Prompt (프롬프트)**: 문맥을 고려한 프롬프트를 사용해 CLIP의 검색 성능을 향상.

FDP는 기존 STR 방법 대비 **4배 빠른 속도**를 유지하면서도 검색 정확도를 4.37% 향상시키는 성능을 보였습니다.

---

### **2. 연구 배경 및 기존 방법 (Related Work)**
#### **2.1 Scene Text Retrieval (STR)**
STR은 특정 쿼리 텍스트를 포함하는 이미지를 찾는 문제입니다. 기존 방법들은 일반적으로 OCR 기반으로 진행되며, 다음과 같은 단계를 거칩니다:
1. **텍스트 감지 (Text Detection)**: 이미지에서 텍스트 영역을 찾음.
2. **텍스트 인식 (Text Recognition)**: 텍스트를 문자 단위로 변환하여 검색.

하지만, OCR 기반 STR은 속도가 느리고, 다국어 또는 다양한 글꼴과 스타일을 다루기 어렵습니다.

#### **2.2 CLIP의 OCR 기능 활용**
최근 CLIP과 같은 **대규모 멀티모달 모델**이 STR에도 활용될 가능성이 제기되었습니다.  
- CLIP은 텍스트-이미지 대응 학습을 통해 OCR 기능을 일부 포함하고 있음.
- 하지만 CLIP이 **텍스트를 직접 탐색하는 것이 아니라, 이미지 내 텍스트의 의미적 관계를 학습**하는 경향이 있음.
- 따라서 STR에 활용하기 위해 CLIP의 제한을 보완할 필요가 있음.

---

### **3. FDP 모델 (FDP Method)**
FDP 모델은 기존 OCR 기반 STR의 한계를 극복하기 위해 **Focus, Distinguish, Prompt** 3단계를 통해 CLIP의 검색 성능을 최적화합니다.

#### **3.1 Focus (CLIP의 텍스트 집중 유도)**
기본 CLIP 모델은 이미지 전체를 분석하지만, 텍스트를 특정하여 처리하지 못합니다. 이를 보완하기 위해:
- **동적 주의 이동 (Dynamic Attention Shift)**: 이미지 내 텍스트가 있는 부분을 강조하는 기법.
- **텍스트 지식 탐색 (Text Knowledge Probing)**: "scene text"와 같은 프롬프트를 활용해 CLIP이 텍스트를 더 인식할 수 있도록 유도.

#### **3.2 Distinguish (의미 기반 텍스트 구별)**
쿼리 단어가 **의미가 명확한 단어(content words)**인지 **기능적 단어(function words)**인지 구별합니다.
- 예: "coffee", "hotel" 같은 단어는 명확한 의미가 있지만, "and", "with" 같은 단어는 CLIP에서 혼동될 가능성이 높음.
- 이를 위해 **비지도 학습 기반 클러스터링**을 사용하여 두 그룹을 분리.

#### **3.3 Prompt (프롬프트 튜닝)**
- **Semantic-aware Prompting**: 쿼리 단어를 학습 가능한 프롬프트로 변환.
- **Distracted Queries Assistance**: 유사한 단어(예: "advice" vs. "advise")를 구분하는 학습 전략 도입.

---

### **4. 실험 및 결과 (Experiments)**
#### **4.1 데이터셋**
- **IIIT-STR** (10,000개 이미지, 50개 쿼리 단어)
- **SVT** (거리 풍경 이미지, 249개 테스트 이미지)
- **TotalText** (복잡한 글꼴과 스타일이 포함된 1,255개 이미지)
- **PSTR (새로운 Phrase-level STR 데이터셋)**: 문장 기반 검색 성능을 테스트하기 위해 36개 문구를 사용.

#### **4.2 실험 결과**
- 기존 STR 모델 대비 **빠른 속도와 높은 정확도**를 달성.
- **IIIT-STR 데이터셋**에서 최적 모델(FDP-L)의 mAP가 기존 SOTA(77.40%) 대비 **89.46%**로 12.06% 향상됨.
- **PSTR 실험**에서 기존 방법보다 높은 정확도를 보이며, 긴 문구 검색에서도 유연하게 대응 가능.

#### **4.3 주요 비교**
| Method | mAP (IIIT-STR) | mAP (SVT) | FPS |
|--------|--------------|------------|------|
| CLIP-RN50 | 52.93% | 65.07% | 76.32 |
| FDP-S (Ours) | 81.77% | 82.56% | 45.11 |
| FDP-B (Ours) | 86.65% | 86.64% | 31.43 |
| FDP-L (Ours) | **89.46%** | **89.63%** | 11.82 |

- FDP는 기존 OCR 기반 방법보다 빠르고, 높은 정확도를 기록.
- 특히 **속도(FPS)** 측면에서도 CLIP 기반이라 OCR-free 방식보다 우수함.

---

### **5. 결론 (Conclusion)**
본 연구에서는 CLIP을 기반으로 한 OCR-free Scene Text Retrieval (STR) 방법인 **FDP 모델**을 제안했습니다.  
- **"Focus, Distinguish, Prompt" 전략을 활용하여 CLIP이 텍스트 검색에 최적화되도록 개선**.
- **속도와 정확도를 동시에 향상**시키면서도 다양한 검색 시나리오(단어 기반, 문구 기반, 속성 기반)에 유연하게 적용 가능.

**➡ 실용적인 응용 가능성:**  
- 제품 이미지 검색  
- 도서/문서 검색 시스템  
- 영상 속 장면 텍스트 검색  

또한 FDP는 CLIP을 STR에 직접 활용한 첫 연구로, 향후 CLIP 기반 텍스트 인식 연구의 기초가 될 수 있습니다.  
소스코드는 공개 예정이며, 향후 OCR-free 방식의 확장성을 연구할 계획입니다.

---

### **요약**
1. **기존 STR 방법**은 OCR 기반으로 복잡하고 느림.
2. **CLIP을 활용한 OCR-free STR**이 가능하지만, 기본 CLIP은 텍스트 인식에 한계가 있음.
3. **FDP 모델(Focus, Distinguish, Prompt)**을 적용해 CLIP을 STR에 최적화.
4. 기존 방법 대비 **더 높은 정확도(4.37% 향상)와 빠른 속도(4배 이상)** 달성.
5. **문구 기반, 속성 기반 검색도 지원 가능**.

➡ **FDP는 STR의 새로운 패러다임을 제시하는 모델로, 향후 다양한 검색 시스템에 적용될 수 있음.**